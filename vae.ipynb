{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1650b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "  def __init__(self, x_dim, hidden_dim, z_dim=10):\n",
    "    super(autoencoder,self).__init__()\n",
    "    self.enc_layer1 = nn.Linear(x_dim, hidden_dim)\n",
    "    self.enc_layer2 = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    self.dec_layer1 = nn.Linear(z_dim, hidden_dim)\n",
    "    self.dec_layer2 = nn.Linear(hidden_dim, x_dim)\n",
    "\n",
    "  def encode(self, x):\n",
    "    x = F.relu(self.enc_layer1(x))\n",
    "    z = F.relu(self.enc_layer2(x))\n",
    "    return z\n",
    "\n",
    "  def decode(self, z):\n",
    "    output = F.relu(self.dec_layer1(z))\n",
    "    output = F.relu(self.dec_layer2(output))\n",
    "    return output\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = self.encode(x)\n",
    "    output = self.decode(z)\n",
    "    return output \n",
    "\n",
    "def loss_function(output, x):\n",
    "  recon_loss = F.mse_loss(output, x, reduction='sum')\n",
    "  return recon_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270b81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = autoencoder(256,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "  def __init__(self, x_dim, hidden_dim, z_dim=10):\n",
    "    super(VAE, self).__init__()\n",
    "    self.enc_layer1 = nn.Linear(x_dim, hidden_dim)\n",
    "    self.enc_layer2_mu = nn.Linear(hidden_dim, z_dim)\n",
    "    self.enc_layer2_logvar = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    self.dec_layer1 = nn.Linear(z_dim, hidden_dim)\n",
    "    self.dec_layer2 = nn.Linear(hidden_dim, x_dim)\n",
    "\n",
    "  def encode(self, x):\n",
    "    x = F.relu(self.enc_layer1(x))\n",
    "    mu = F.relu(self.enc_layer2_mu(x))\n",
    "    logvar = F.relu(self.enc_layer2_logvar(x))\n",
    "    return mu,logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar):\n",
    "    std = torch.exp(logvar/2)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = mu + std*eps\n",
    "    return z\n",
    "\n",
    "  def decoder(self, z):\n",
    "    output = F.relu(self.dec_layer1(z))\n",
    "    output = F.relu(self.dec_layer2(output))\n",
    "    return output\n",
    "\n",
    "  def forward(self, x):\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    output = self.decode(z)\n",
    "    return output, z, mu, logvar\n",
    "\n",
    "def loss_function(output, x, mu, logvar):\n",
    "  renc_loss = F.mse_loss(output, x, reduction='sum') / batch_size\n",
    "  kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "  return renc_loss + 0.002 * kl_loss\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
